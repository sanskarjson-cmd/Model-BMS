{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5715f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas:\n",
    "# - Used to load CSV files\n",
    "# - Used to clean, merge, and manipulate patient data tables\n",
    "# - Used for feature engineering (handling missing values, encoding, etc.)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# numpy:\n",
    "# - Used for numerical operations\n",
    "# - Used to create sample weights (event vs censored)\n",
    "# - Used for mathematical calculations like RMSE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# datetime:\n",
    "# - Used to work with dates and times\n",
    "# - Helps calculate survival time (diagnosis ‚Üí death / last visit)\n",
    "# - Ensures correct date arithmetic\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# GradientBoostingRegressor:\n",
    "# - Machine learning model used to predict survival time\n",
    "# - Builds multiple decision trees sequentially\n",
    "# - Captures non-linear relationships and feature interactions\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# train_test_split:\n",
    "# - Splits data into training and testing sets\n",
    "# - Ensures unbiased model evaluation\n",
    "#\n",
    "# cross_val_score:\n",
    "# - Used for cross-validation (optional improvement step)\n",
    "# - Helps estimate model stability across multiple data splits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "# concordance_index:\n",
    "# - Evaluation metric specific to survival analysis\n",
    "# - Measures how well the model ranks patients by survival time\n",
    "# - Properly handles censored data\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "\n",
    "# matplotlib.pyplot:\n",
    "# - Used for plotting and visualization\n",
    "# - Can be used for:\n",
    "#   ‚Ä¢ Feature importance plots\n",
    "#   ‚Ä¢ Predicted vs actual survival curves\n",
    "#   ‚Ä¢ Risk group visualizatio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171ac4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GRADIENT BOOSTING SURVIVAL MODEL\n",
      "======================================================================\n",
      "\n",
      "Gradient Boosting as alternative to Cox Proportional Hazards:\n",
      "  ‚úì Tree-based machine learning model\n",
      "  ‚úì No proportional hazards assumption needed\n",
      "  ‚úì Captures non-linear relationships automatically\n",
      "  ‚úì Handles feature interactions\n",
      "  ‚úì Uses sklearn (no extra dependencies)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"GRADIENT BOOSTING SURVIVAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "print(\"  ‚úì Tree-based machine learning model\")\n",
    "print(\"  ‚úì Captures non-linear relationships automatically\")\n",
    "print(\"  ‚úì Handles feature interactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af467dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì All datasets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "base_path = r\"C:\\Users\\sanskar.kashyap\\OneDrive - Mu Sigma Business Solutions Pvt. Ltd\\Desktop\\Model-BMS\"\n",
    "df_nsclc = pd.read_csv(f'{base_path}\\\\nscexpnd_nsclc_2506.csv')\n",
    "df_mortality = pd.read_csv(f'{base_path}\\\\nscexpnd_mortality_v2_2506.csv')\n",
    "df_demographics = pd.read_csv(f'{base_path}\\\\nscexpnd_demographics_2506.csv')\n",
    "df_ecog = pd.read_csv(f'{base_path}\\\\nscexpnd_ecog_2506.csv')\n",
    "df_visits = pd.read_csv(f'{base_path}\\\\nscexpnd_visit_2506.csv')\n",
    "\n",
    "print(\"\\n‚úì All datasets loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212b3ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dropped 61 invalid OS rows\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Keep ONLY NSCLC patients\n",
    "# Why?\n",
    "# - Our study is about lung cancer (NSCLC)\n",
    "# - Other cancer patients would confuse the model\n",
    "cohort = df_nsclc[df_nsclc[\"isnsclc\"] == 1].copy()\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Define the start of survival time\n",
    "# Why?\n",
    "# - Survival time always starts from diagnosis date\n",
    "# - All patients must have a common \"time zero\"\n",
    "cohort[\"start_date\"] = pd.to_datetime(cohort[\"nsclcdiagnosisdate\"])\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Select only required mortality columns\n",
    "# Why?\n",
    "# - We only need patient ID and death date\n",
    "# - Reduces memory usage and keeps data clean\n",
    "mort = df_mortality[[\"patientid\", \"dateofdeath\"]].copy()\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Convert death date to datetime format\n",
    "# Why?\n",
    "# - Date calculations require proper datetime type\n",
    "# - Strings cannot be used for date subtraction\n",
    "mort[\"dateofdeath\"] = pd.to_datetime(mort[\"dateofdeath\"])\n",
    "\n",
    "\n",
    "# 5Ô∏è‚É£ Merge death information with patient cohort\n",
    "# Why?\n",
    "# - Adds death information to each patient\n",
    "# - LEFT join keeps all patients (alive + dead)\n",
    "cohort = cohort.merge(mort, on=\"patientid\", how=\"left\")\n",
    "\n",
    "\n",
    "# 6Ô∏è‚É£ Create event indicator (core survival concept)\n",
    "# Why?\n",
    "# - event = 1 ‚Üí patient died (observed outcome)\n",
    "# - event = 0 ‚Üí patient alive (censored)\n",
    "# - Survival models NEED this information\n",
    "cohort[\"event\"] = cohort[\"dateofdeath\"].notna().astype(int)\n",
    "\n",
    "\n",
    "# 7Ô∏è‚É£ Find the last hospital visit for each patient\n",
    "# Why?\n",
    "# - For alive patients, we only know survival until last visit\n",
    "# - This defines the censoring time\n",
    "last_visit = df_visits.groupby(\"patientid\")[\"visitdate\"].max().reset_index()\n",
    "\n",
    "\n",
    "# 8Ô∏è‚É£ Convert visit date to datetime\n",
    "# Why?\n",
    "# - Required for accurate time calculations\n",
    "last_visit[\"visitdate\"] = pd.to_datetime(last_visit[\"visitdate\"])\n",
    "\n",
    "\n",
    "# 9Ô∏è‚É£ Merge last visit date into cohort\n",
    "# Why?\n",
    "# - Adds follow-up information for censored patients\n",
    "cohort = cohort.merge(last_visit, on=\"patientid\", how=\"left\")\n",
    "\n",
    "\n",
    "# üîü Define study end date (data cutoff)\n",
    "# Why?\n",
    "# - Prevents survival time from extending beyond data availability\n",
    "# - Standard practice in clinical studies\n",
    "DATA_CUTOFF = pd.to_datetime(\"2025-01-01\")\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Initialize end_date using date of death\n",
    "# Why?\n",
    "# - For patients who died, survival ends at death\n",
    "cohort[\"end_date\"] = cohort[\"dateofdeath\"]\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ For alive patients, use last visit date as end_date\n",
    "# Why?\n",
    "# - We don't know when they will die\n",
    "# - We only know they survived until last visit\n",
    "cohort.loc[cohort[\"event\"] == 0, \"end_date\"] = \\\n",
    "    cohort.loc[cohort[\"event\"] == 0, \"visitdate\"]\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£3Ô∏è‚É£ Handle patients with no death and no visit record\n",
    "# Why?\n",
    "# - Avoid missing end dates\n",
    "# - Assume survival until study cutoff\n",
    "cohort[\"end_date\"] = cohort[\"end_date\"].fillna(DATA_CUTOFF)\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£4Ô∏è‚É£ Calculate overall survival time (OS)\n",
    "# Why?\n",
    "# - This is the TARGET variable for the model\n",
    "# - Measures how long the patient survived after diagnosis\n",
    "cohort[\"os_time_days\"] = (cohort[\"end_date\"] - cohort[\"start_date\"]).dt.days\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£5Ô∏è‚É£ Ensure survival time is numeric\n",
    "# Why?\n",
    "# - Prevents errors during model training\n",
    "# - Converts invalid values to NaN\n",
    "cohort[\"os_time_days\"] = pd.to_numeric(cohort[\"os_time_days\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£6Ô∏è‚É£ Identify invalid survival times\n",
    "# Why?\n",
    "# - Survival cannot be negative or zero\n",
    "# - Missing values break survival analysis\n",
    "invalid_rows = cohort[\"os_time_days\"].isna() | (cohort[\"os_time_days\"] <= 0)\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£7Ô∏è‚É£ Log how many rows are removed\n",
    "# Why?\n",
    "# - Transparency and data quality check\n",
    "print(f\"‚úì Dropped {invalid_rows.sum()} invalid OS rows\")\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£8Ô∏è‚É£ Remove invalid rows from the cohort\n",
    "# Why?\n",
    "# - Ensures clean, meaningful data for modeling\n",
    "# - Improves model reliability\n",
    "cohort = cohort.loc[~invalid_rows].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af105331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- C. Merge Demographics & ECOG ---\n",
    "\n",
    "# 1Ô∏è‚É£ Merge demographic information into the cohort\n",
    "# Why?\n",
    "# - Adds basic patient characteristics needed for survival prediction\n",
    "# - Age, sex, and race are known prognostic factors\n",
    "# - LEFT join keeps all patients even if demographic info is missing\n",
    "cohort = cohort.merge(\n",
    "    df_demographics[[\"patientid\", \"birthyear\", \"birthsex\", \"race\"]],\n",
    "    on=\"patientid\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Calculate patient's age at diagnosis\n",
    "# Why?\n",
    "# - Age at diagnosis affects survival, not current age\n",
    "# - Survival models need age as a numerical feature\n",
    "cohort[\"age\"] = cohort[\"start_date\"].dt.year - cohort[\"birthyear\"]\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Create a working copy of ECOG data\n",
    "# Why?\n",
    "# - Avoids modifying the original ECOG dataset\n",
    "ecog = df_ecog.copy()\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Convert ECOG date to datetime format\n",
    "# Why?\n",
    "# - Required to compare ECOG date with diagnosis date\n",
    "# - String dates cannot be compared reliably\n",
    "ecog[\"ecogdate\"] = pd.to_datetime(ecog[\"ecogdate\"])\n",
    "\n",
    "\n",
    "# 5Ô∏è‚É£ Attach diagnosis date to each ECOG record\n",
    "# Why?\n",
    "# - Allows filtering ECOG values taken BEFORE diagnosis\n",
    "# - Prevents using post-diagnosis information (data leakage)\n",
    "ecog = ecog.merge(\n",
    "    cohort[[\"patientid\", \"start_date\"]],\n",
    "    on=\"patientid\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "# 6Ô∏è‚É£ Keep only ECOG measurements taken on or before diagnosis\n",
    "# Why?\n",
    "# - ECOG after diagnosis may be influenced by disease progression\n",
    "# - Using post-diagnosis values would leak future information\n",
    "ecog = ecog[ecog[\"ecogdate\"] <= ecog[\"start_date\"]]\n",
    "\n",
    "\n",
    "# 7Ô∏è‚É£ Select the most recent ECOG BEFORE diagnosis (baseline ECOG)\n",
    "# Why?\n",
    "# - Closest ECOG before diagnosis best represents patient condition at baseline\n",
    "# - Group by patient and take the latest valid ECOG\n",
    "baseline_ecog = (\n",
    "    ecog\n",
    "    .sort_values(\"ecogdate\")\n",
    "    .groupby(\"patientid\")\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# 8Ô∏è‚É£ Merge baseline ECOG into main cohort\n",
    "# Why?\n",
    "# - Adds functional status as an important survival predictor\n",
    "# - LEFT join keeps patients even if ECOG is missing\n",
    "cohort = cohort.merge(\n",
    "    baseline_ecog[[\"patientid\", \"ecogvalue\"]],\n",
    "    on=\"patientid\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c07ca245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Final cohort: 1289 patients\n",
      "  - Events (deaths): 708\n",
      "  - Censored: 581\n"
     ]
    }
   ],
   "source": [
    "# --- D. Prepare Modeling Dataset ---\n",
    "\n",
    "# 1Ô∏è‚É£ Select only the required columns for survival modeling\n",
    "# Why?\n",
    "# - Keeps the dataset clean and focused\n",
    "# - Removes unused columns that could confuse the model\n",
    "# - Each selected column has clinical or predictive importance\n",
    "os_df = cohort[[\n",
    "    \"patientid\",        # Unique patient identifier (not used for modeling, only tracking)\n",
    "    \"os_time_days\",     # Target variable: overall survival time in days\n",
    "    \"event\",            # Event indicator: 1 = death, 0 = censored (alive)\n",
    "    \"age\",              # Age at diagnosis (strong survival predictor)\n",
    "    \"birthsex\",         # Biological sex (may affect outcomes)\n",
    "    \"race\",             # Race (can capture demographic outcome differences)\n",
    "    \"ecogvalue\",        # Baseline functional status of patient\n",
    "    \"groupstage\",       # Cancer stage at diagnosis (severity indicator)\n",
    "    \"ismetastatic\",     # Whether cancer has spread to distant organs\n",
    "    \"histology\",        # Cancer subtype (biological behavior differs)\n",
    "    \"smokingstatus\",    # Smoking history (risk and prognosis factor)\n",
    "    \"hassurgery\"        # Whether patient underwent surgery (treatment effect)\n",
    "]].copy()\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Print total number of patients in final dataset\n",
    "# Why?\n",
    "# - Sanity check to ensure no unexpected data loss\n",
    "# - Confirms cohort size before modeling\n",
    "print(f\"\\n‚úì Final cohort: {len(os_df)} patients\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Print number of death events\n",
    "# Why?\n",
    "# - Shows how many patients have observed outcomes\n",
    "# - Important for survival model reliability\n",
    "print(f\"  - Events (deaths): {os_df['event'].sum()}\")\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Print number of censored patients\n",
    "# Why?\n",
    "# - Indicates how many patients are still alive or lost to follow-up\n",
    "# - Survival models must handle censoring properly\n",
    "print(f\"  - Censored: {(os_df['event'] == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84ef6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- E. Feature Engineering ---\n",
    "\n",
    "# 1Ô∏è‚É£ Handle missing ECOG values\n",
    "# Why?\n",
    "# - Some patients do not have ECOG recorded\n",
    "# - ECOG is an important predictor of survival\n",
    "# - Dropping these patients would reduce sample size\n",
    "# - Median is used because it is robust to extreme values\n",
    "os_df[\"ecogvalue\"] = os_df[\"ecogvalue\"].fillna(\n",
    "    os_df[\"ecogvalue\"].median()\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Handle missing surgery information\n",
    "# Why?\n",
    "# - Missing surgery usually means surgery was not performed\n",
    "# - Converting to 0/1 makes it usable for ML models\n",
    "# - Ensures consistent data type\n",
    "os_df[\"hassurgery\"] = (\n",
    "    os_df[\"hassurgery\"]\n",
    "    .fillna(0)          # Assume no surgery if missing\n",
    "    .astype(int)        # Convert to binary integer (0 or 1)\n",
    ")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Handle missing age values\n",
    "# Why?\n",
    "# - Age is essential for survival prediction\n",
    "# - Missing age cannot be left as NaN\n",
    "# - Median preserves population structure better than mean\n",
    "os_df[\"age\"] = os_df[\"age\"].fillna(\n",
    "    os_df[\"age\"].median()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a427ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same dummy encoding as Cox for fair comparison\n",
    "# Why?\n",
    "# - Cox model cannot handle text (categorical) variables directly\n",
    "# - Gradient Boosting also works better with numeric inputs\n",
    "# - Using the SAME encoding ensures fair performance comparison\n",
    "cat_cols = [\n",
    "    \"birthsex\",        # Male / Female\n",
    "    \"race\",            # White / Black / Asian / etc.\n",
    "    \"groupstage\",      # Cancer stage (I, II, III, IV)\n",
    "    \"histology\",       # Cancer subtype\n",
    "    \"smokingstatus\"    # Smoking history\n",
    "]\n",
    "\n",
    "\n",
    "# Convert categorical (text) columns into numeric dummy variables\n",
    "# Why?\n",
    "# - Machine learning models cannot understand text labels\n",
    "# - Each category is converted into a 0/1 column\n",
    "# - This process is called One-Hot Encoding\n",
    "os_df_encoded = pd.get_dummies(\n",
    "    os_df,\n",
    "    columns=cat_cols,   # Columns to be encoded\n",
    "    drop_first=True     # Drop one category to avoid redundancy\n",
    ")\n",
    "\n",
    "\n",
    "# Remove patient identifier from modeling data\n",
    "# Why?\n",
    "# - patientid has no predictive meaning\n",
    "# - Keeping it could cause data leakage or overfitting\n",
    "# - It is only useful for tracking, not learning\n",
    "model_df = os_df_encoded.drop(columns=[\"patientid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d0b35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Train set: 1031 patients (566 events)\n",
      "‚úì Test set: 258 patients (142 events)\n"
     ]
    }
   ],
   "source": [
    "# --- F. Train-Test Split ---\n",
    "\n",
    "# 1Ô∏è‚É£ Split the data into training and testing sets\n",
    "# Why?\n",
    "# - Training data is used to teach the model patterns\n",
    "# - Testing data is used to check if the model works on new patients\n",
    "# - Prevents the model from memorizing instead of learning\n",
    "train_df, test_df = train_test_split(\n",
    "    model_df,              # Final dataset after encoding and cleaning\n",
    "    test_size=0.2,         # 20% data for testing, 80% for training\n",
    "    random_state=42,       # Ensures the split is reproducible\n",
    "    stratify=model_df[\"event\"]  # Keeps same death/alive ratio in both sets\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Print training set details\n",
    "# Why?\n",
    "# - Confirms how many patients are used to train the model\n",
    "# - Shows number of death events available for learning\n",
    "print(f\"\\n‚úì Train set: {len(train_df)} patients ({train_df['event'].sum()} events)\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Print test set details\n",
    "# Why?\n",
    "# - Confirms how many patients are used for evaluation\n",
    "# - Ensures enough death events exist for fair testing\n",
    "print(f\"‚úì Test set: {len(test_df)} patients ({test_df['event'].sum()} events)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc31205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING GRADIENT BOOSTING MODEL\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- G. Train Gradient Boosting Model ---\n",
    "\n",
    "# 1Ô∏è‚É£ Print section header (for readability only)\n",
    "# Why?\n",
    "# - Makes output easier to read\n",
    "# - Helps track progress during long runs\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING GRADIENT BOOSTING MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Prepare training INPUT features (X)\n",
    "# Why?\n",
    "# - X contains only patient characteristics\n",
    "# - Model uses X to learn patterns\n",
    "# - Survival time and event must NOT be included as inputs\n",
    "X_train = train_df.drop(\n",
    "    columns=[\n",
    "        \"os_time_days\",  # Target variable (what we want to predict)\n",
    "        \"event\"          # Outcome indicator (used only for evaluation/weighting)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Prepare training TARGET variable (y)\n",
    "# Why?\n",
    "# - y is what the model tries to predict\n",
    "# - Here: overall survival time in days\n",
    "y_train = train_df[\"os_time_days\"]\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Prepare testing INPUT features (X)\n",
    "# Why?\n",
    "# - Used to test model performance on unseen patients\n",
    "X_test = test_df.drop(\n",
    "    columns=[\n",
    "        \"os_time_days\",\n",
    "        \"event\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 5Ô∏è‚É£ Prepare testing TARGET variable (y)\n",
    "# Why?\n",
    "# - Used only for evaluation\n",
    "# - Model NEVER sees these values during training\n",
    "y_test = test_df[\"os_time_days\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd64a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Gradient Boosting Regressor...\n",
      "  - Predicting survival time (days)\n",
      "  - Weighting events more than censored patients\n",
      "  - Using Huber loss (robust to outliers)\n",
      "\n",
      "‚úì Gradient Boosting model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create sample weights: events get full weight, censored get partial weight\n",
    "# Why?\n",
    "# - Patients who died have exact survival time\n",
    "# - Censored patients have incomplete survival information\n",
    "# - We want the model to trust death events more\n",
    "train_weights = np.where(\n",
    "    train_df[\"event\"] == 1,    # If patient died\n",
    "    1.0,                       # Full importance\n",
    "    0.5                        # Lower importance for censored patients\n",
    ")\n",
    "\n",
    "\n",
    "# Print training information (for clarity only)\n",
    "print(\"\\nTraining Gradient Boosting Regressor...\")\n",
    "print(\"  - Predicting survival time (days)\")\n",
    "print(\"  - Weighting events more than censored patients\")\n",
    "print(\"  - Using Huber loss (robust to outliers)\")\n",
    "\n",
    "\n",
    "# Initialize Gradient Boosting Regressor\n",
    "# This model builds many small decision trees sequentially\n",
    "gb_model = GradientBoostingRegressor(\n",
    "\n",
    "    n_estimators=100,          \n",
    "    # Number of trees\n",
    "    # More trees = more learning capacity (but slower)\n",
    "\n",
    "    learning_rate=0.05,        \n",
    "    # Controls how much each tree contributes\n",
    "    # Smaller value = slower, safer learning\n",
    "\n",
    "    max_depth=4,               \n",
    "    # Maximum depth of each tree\n",
    "    # Controls how complex each tree can be\n",
    "\n",
    "    min_samples_split=20,      \n",
    "    # Minimum samples required to split a node\n",
    "    # Prevents overfitting on small groups\n",
    "\n",
    "    min_samples_leaf=10,       \n",
    "    # Minimum samples allowed in a leaf node\n",
    "    # Ensures predictions are based on enough patients\n",
    "\n",
    "    subsample=0.8,             \n",
    "    # Each tree uses only 80% of training data\n",
    "    # Adds randomness and improves generalization\n",
    "\n",
    "    max_features='sqrt',       \n",
    "    # Each split considers only sqrt(number of features)\n",
    "    # Reduces correlation between trees\n",
    "\n",
    "    loss='huber',              \n",
    "    # Huber loss is robust to extreme survival times\n",
    "    # Combines advantages of MAE and MSE\n",
    "\n",
    "    alpha=0.9,                 \n",
    "    # Controls sensitivity of Huber loss to outliers\n",
    "\n",
    "    random_state=42,           \n",
    "    # Ensures reproducible results\n",
    "\n",
    "    verbose=0                  \n",
    "    # No extra output during training\n",
    ")\n",
    "\n",
    "\n",
    "# Train the Gradient Boosting model\n",
    "# Why?\n",
    "# - Model learns patterns linking patient features to survival time\n",
    "# - Sample weights ensure deaths influence learning more\n",
    "gb_model.fit(\n",
    "    X_train,                   # Patient features\n",
    "    y_train,                   # Survival time in days\n",
    "    sample_weight=train_weights\n",
    ")\n",
    "\n",
    "\n",
    "# Confirm training completion\n",
    "print(\"\\n‚úì Gradient Boosting model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1d6a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- H. Model Evaluation ---\n",
    "\n",
    "# 1Ô∏è‚É£ Print a visual separator line\n",
    "# Why?\n",
    "# - Makes console output clean and organized\n",
    "# - Helps clearly separate training output from evaluation output\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Print section title\n",
    "# Why?\n",
    "# - Indicates that model training is finished\n",
    "# - Everything printed after this relates to model performance\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Print another separator line\n",
    "# Why?\n",
    "# - Improves readability\n",
    "# - Makes logs easier to interpret during debugging or presentations\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0721ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "# 1Ô∏è‚É£ Predict survival time for TRAINING patients\n",
    "# Why?\n",
    "# - Checks how well the model learned patterns\n",
    "# - High performance here means the model fit the data\n",
    "y_train_pred = gb_model.predict(X_train)\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Predict survival time for TEST patients\n",
    "# Why?\n",
    "# - Tests model performance on unseen patients\n",
    "# - This is the TRUE measure of model quality\n",
    "y_test_pred = gb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f403a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate C-index\n",
    "# Why?\n",
    "# - Survival models are evaluated by ranking, not exact values\n",
    "# - We care whether the model correctly orders patients by survival\n",
    "\n",
    "# For survival time predictions:\n",
    "# - Higher predicted time = better prognosis (lives longer)\n",
    "# - So we pass predictions directly (no sign change needed)\n",
    "\n",
    "# 1Ô∏è‚É£ C-index on TRAINING data\n",
    "# Why?\n",
    "# - Measures how well the model ranks patients it learned from\n",
    "train_ci = concordance_index(\n",
    "    train_df[\"os_time_days\"],   # True survival time\n",
    "    y_train_pred,               # Predicted survival time\n",
    "    train_df[\"event\"]           # Event indicator (1 = death, 0 = censored)\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ C-index on TEST data\n",
    "# Why?\n",
    "# - Measures how well the model ranks NEW patients\n",
    "# - This is the key metric to judge real performance\n",
    "test_ci = concordance_index(\n",
    "    test_df[\"os_time_days\"],\n",
    "    y_test_pred,\n",
    "    test_df[\"event\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ecfb5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concordance Index (C-index):\n",
      "  Train: 0.7442\n",
      "  Test:  0.7247\n",
      "\n",
      "  üéâ Improvement: +0.66%\n"
     ]
    }
   ],
   "source": [
    "# Print C-index results\n",
    "# Why?\n",
    "# - Shows how well the model ranks patients by survival\n",
    "# - Separately reports performance on training and testing data\n",
    "print(\"\\nConcordance Index (C-index):\")\n",
    "print(f\"  Train: {train_ci:.4f}\")   # Model performance on training data\n",
    "print(f\"  Test:  {test_ci:.4f}\")    # Model performance on unseen test data\n",
    "\n",
    "\n",
    "# Compare test C-index against a reference benchmark (0.72)\n",
    "# Why 0.72?\n",
    "# - This can represent:\n",
    "#   ‚Ä¢ A baseline Cox model\n",
    "#   ‚Ä¢ A previous model\n",
    "#   ‚Ä¢ A clinically acceptable threshold\n",
    "if test_ci > 0.72:\n",
    "    \n",
    "    # Calculate percentage improvement over the benchmark\n",
    "    improvement = ((test_ci - 0.72) / 0.72) * 100\n",
    "    \n",
    "    # Print improvement message\n",
    "    print(f\"\\n  üéâ Improvement: +{improvement:.2f}%\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Calculate percentage decline from the benchmark\n",
    "    decline = ((0.72 - test_ci) / 0.72) * 100\n",
    "    \n",
    "    # Print decline warning\n",
    "    print(f\"\\n  ‚ö†Ô∏è  Lower by: -{decline:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5a925fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Accuracy (for observed deaths):\n",
      "  Mean Absolute Error:  499 days (16.6 months)\n",
      "  Root Mean Sq Error:   703 days (23.4 months)\n"
     ]
    }
   ],
   "source": [
    "# Additional metrics for observed events\n",
    "\n",
    "# 1Ô∏è‚É£ Create a mask for patients who actually died (event = 1)\n",
    "# Why?\n",
    "# - For these patients, we know the true survival time exactly\n",
    "# - Error metrics like MAE and RMSE require exact outcomes\n",
    "train_events_mask = train_df[\"event\"] == 1\n",
    "test_events_mask = test_df[\"event\"] == 1\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Check if there are any death events in the test set\n",
    "# Why?\n",
    "# - MAE/RMSE cannot be computed if no patient died\n",
    "# - Prevents division by zero or meaningless metrics\n",
    "if test_events_mask.sum() > 0:\n",
    "    \n",
    "    # 3Ô∏è‚É£ Import error metrics\n",
    "    # Why?\n",
    "    # - MAE measures average absolute prediction error\n",
    "    # - RMSE penalizes large errors more heavily\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    \n",
    "    \n",
    "    # 4Ô∏è‚É£ Calculate Mean Absolute Error (MAE) for deceased patients only\n",
    "    # Why?\n",
    "    # - Measures average prediction mistake in days\n",
    "    # - Uses only patients with known survival time\n",
    "    mae = mean_absolute_error(\n",
    "        y_test[test_events_mask],      # True survival time\n",
    "        y_test_pred[test_events_mask]  # Predicted survival time\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 5Ô∏è‚É£ Calculate Root Mean Squared Error (RMSE)\n",
    "    # Why?\n",
    "    # - Highlights large prediction errors\n",
    "    # - More sensitive to outliers than MAE\n",
    "    rmse = np.sqrt(\n",
    "        mean_squared_error(\n",
    "            y_test[test_events_mask],\n",
    "            y_test_pred[test_events_mask]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 6Ô∏è‚É£ Print error metrics in days and months\n",
    "    # Why?\n",
    "    # - Days are precise\n",
    "    # - Months are easier to interpret clinically\n",
    "    print(f\"\\nPrediction Accuracy (for observed deaths):\")\n",
    "    print(f\"  Mean Absolute Error:  {mae:.0f} days ({mae/30:.1f} months)\")\n",
    "    print(f\"  Root Mean Sq Error:   {rmse:.0f} days ({rmse/30:.1f} months)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a3f23f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE\n",
      "======================================================================\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "(These features have the strongest impact on survival predictions)\n",
      "\n",
      "  hassurgery                          0.2980 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  age                                 0.1689 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  groupstage_Stage IA                 0.1218 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  groupstage_Stage IV                 0.1054 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  race_White                          0.0499 ‚ñà‚ñà‚ñà‚ñà\n",
      "  groupstage_Stage I                  0.0368 ‚ñà‚ñà‚ñà\n",
      "  groupstage_Stage IB                 0.0307 ‚ñà‚ñà‚ñà\n",
      "  smokingstatus_No history of smoking 0.0290 ‚ñà‚ñà\n",
      "  ismetastatic                        0.0231 ‚ñà‚ñà\n",
      "  groupstage_Stage IVB                0.0200 ‚ñà‚ñà\n"
     ]
    }
   ],
   "source": [
    "# --- I. Feature Importance ---\n",
    "\n",
    "# 1Ô∏è‚É£ Print section header\n",
    "# Why?\n",
    "# - Clearly separates feature importance output\n",
    "# - Improves readability of results\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Create a table of feature importance scores\n",
    "# Why?\n",
    "# - Tree-based models can measure how much each feature\n",
    "#   contributes to reducing prediction error\n",
    "feature_importance = pd.DataFrame({\n",
    "\n",
    "    'Feature': X_train.columns,  \n",
    "    # Name of each input feature used by the model\n",
    "\n",
    "    'Importance': gb_model.feature_importances_\n",
    "    # Numerical score showing how influential each feature is\n",
    "\n",
    "}).sort_values(\n",
    "    'Importance',\n",
    "    ascending=False   # Sort from most important to least important\n",
    ")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Print heading for top features\n",
    "# Why?\n",
    "# - Focuses attention on the most influential variables\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(\"(These features have the strongest impact on survival predictions)\\n\")\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Print top 10 features with a visual bar\n",
    "# Why?\n",
    "# - Makes importance easier to interpret visually\n",
    "# - Bars help compare features at a glance\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    \n",
    "    # Create a simple bar using block characters\n",
    "    bar = \"‚ñà\" * int(row['Importance'] * 100)\n",
    "    \n",
    "    # Print feature name, importance score, and bar\n",
    "    print(f\"  {row['Feature']:<35} {row['Importance']:.4f} {bar}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6c3d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RISK STRATIFICATION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- J. Risk Stratification ---\n",
    "\n",
    "# 1Ô∏è‚É£ Print section header\n",
    "# Why?\n",
    "# - Clearly marks the start of risk stratification\n",
    "# - Separates this analysis from previous evaluation steps\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RISK STRATIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Create a copy of the test dataset\n",
    "# Why?\n",
    "# - We want to attach predictions without modifying original test data\n",
    "# - Keeps raw test data safe for future analysis\n",
    "test_results = test_df.copy()\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Add predicted survival time to test data\n",
    "# Why?\n",
    "# - Allows direct comparison between predicted and actual survival\n",
    "# - Required for grouping patients by predicted risk\n",
    "test_results['predicted_survival'] = y_test_pred\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Create a risk score\n",
    "# Why?\n",
    "# - Risk is the inverse of survival time\n",
    "# - Shorter predicted survival = higher risk\n",
    "# - Negative sign converts survival prediction into risk ranking\n",
    "test_results['risk_score'] = -y_test_pred  # Lower survival ‚Üí higher risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d820858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk Group Performance:\n",
      "\n",
      "  High Risk (n=86):\n",
      "    Predicted Median Survival: 388 days (12.9 months)\n",
      "    Actual Median Survival:    257 days (8.6 months)\n",
      "    Death Event Rate:          72.1%\n",
      "\n",
      "  Medium Risk (n=86):\n",
      "    Predicted Median Survival: 594 days (19.8 months)\n",
      "    Actual Median Survival:    513 days (17.1 months)\n",
      "    Death Event Rate:          57.0%\n",
      "\n",
      "  Low Risk (n=86):\n",
      "    Predicted Median Survival: 1234 days (41.1 months)\n",
      "    Actual Median Survival:    1238 days (41.3 months)\n",
      "    Death Event Rate:          36.0%\n"
     ]
    }
   ],
   "source": [
    "# Create risk groups based on predicted survival\n",
    "\n",
    "# 1Ô∏è‚É£ Divide patients into 3 risk groups using predicted survival\n",
    "# Why?\n",
    "# - Doctors prefer categories (High / Medium / Low risk)\n",
    "# - q=3 splits patients into equal-sized groups (tertiles)\n",
    "test_results['risk_group'] = pd.qcut(\n",
    "    test_results['predicted_survival'],   # Predicted survival time\n",
    "    q=3,                                  # Number of groups\n",
    "    labels=['High Risk', 'Medium Risk', 'Low Risk']\n",
    "    # Lower survival ‚Üí High Risk\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Print heading for risk group evaluation\n",
    "# Why?\n",
    "# - Clearly separates results by risk category\n",
    "print(\"\\nRisk Group Performance:\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Loop through each risk group\n",
    "# Why?\n",
    "# - Allows separate evaluation of High, Medium, and Low risk patients\n",
    "for group in ['High Risk', 'Medium Risk', 'Low Risk']:\n",
    "    \n",
    "    # 4Ô∏è‚É£ Select patients belonging to the current risk group\n",
    "    group_data = test_results[test_results['risk_group'] == group]\n",
    "    \n",
    "    \n",
    "    # 5Ô∏è‚É£ Count number of patients in this group\n",
    "    # Why?\n",
    "    # - Ensures groups are balanced\n",
    "    n = len(group_data)\n",
    "    \n",
    "    \n",
    "    # 6Ô∏è‚É£ Calculate median predicted survival\n",
    "    # Why?\n",
    "    # - Median is robust to extreme survival values\n",
    "    pred_median = group_data['predicted_survival'].median()\n",
    "    \n",
    "    \n",
    "    # 7Ô∏è‚É£ Calculate median actual survival\n",
    "    # Why?\n",
    "    # - Allows comparison between prediction and reality\n",
    "    actual_median = group_data['os_time_days'].median()\n",
    "    \n",
    "    \n",
    "    # 8Ô∏è‚É£ Calculate death rate in the group\n",
    "    # Why?\n",
    "    # - High-risk group should have higher death rate\n",
    "    # - Validates that stratification is meaningful\n",
    "    event_rate = group_data['event'].mean() * 100\n",
    "    \n",
    "    \n",
    "    # 9Ô∏è‚É£ Print group-level results\n",
    "    print(f\"\\n  {group} (n={n}):\")\n",
    "    print(f\"    Predicted Median Survival: {pred_median:.0f} days ({pred_median/30:.1f} months)\")\n",
    "    print(f\"    Actual Median Survival:    {actual_median:.0f} days ({actual_median/30:.1f} months)\")\n",
    "    print(f\"    Death Event Rate:          {event_rate:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9585d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXAMPLE PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "First 5 patients in test set:\n",
      "\n",
      "Patient 1:\n",
      "  Predicted Survival: 1828 days (60.9 months)\n",
      "  Actual Survival:    805 days (26.8 months) [Censored]\n",
      "  Age: 56, ECOG: 1, Metastatic: No, Surgery: Yes\n",
      "\n",
      "Patient 2:\n",
      "  Predicted Survival: 260 days (8.7 months)\n",
      "  Actual Survival:    89 days (3.0 months) [Died]\n",
      "  Age: 75, ECOG: 2, Metastatic: Yes, Surgery: No\n",
      "  Prediction Error:   171 days (5.7 months)\n",
      "\n",
      "Patient 3:\n",
      "  Predicted Survival: 1228 days (40.9 months)\n",
      "  Actual Survival:    2695 days (89.8 months) [Died]\n",
      "  Age: 76, ECOG: 1, Metastatic: No, Surgery: Yes\n",
      "  Prediction Error:   1467 days (48.9 months)\n",
      "\n",
      "Patient 4:\n",
      "  Predicted Survival: 1198 days (39.9 months)\n",
      "  Actual Survival:    489 days (16.3 months) [Censored]\n",
      "  Age: 51, ECOG: 1, Metastatic: Yes, Surgery: Yes\n",
      "\n",
      "Patient 5:\n",
      "  Predicted Survival: 1090 days (36.3 months)\n",
      "  Actual Survival:    2762 days (92.1 months) [Censored]\n",
      "  Age: 71, ECOG: 1, Metastatic: No, Surgery: Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- K. Example Predictions ---\n",
    "\n",
    "# 1Ô∏è‚É£ Print section header\n",
    "# Why?\n",
    "# - Clearly marks the start of example predictions\n",
    "# - Makes output easier to read\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Print explanation text\n",
    "# Why?\n",
    "# - Tells the reader what will be shown next\n",
    "print(\"\\nFirst 5 patients in test set:\\n\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Convert true survival values to NumPy array\n",
    "# Why?\n",
    "# - Makes indexing easier inside the loop\n",
    "y_test_values = y_test.values\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Loop through first 5 patients in test data\n",
    "# Why?\n",
    "# - Shows real examples instead of abstract metrics\n",
    "# - Limits output so it stays readable\n",
    "for i in range(min(5, len(test_df))):\n",
    "\n",
    "    # 5Ô∏è‚É£ Get predicted survival time for patient i\n",
    "    # Why?\n",
    "    # - This is what the model predicts\n",
    "    pred_survival = y_test_pred[i]\n",
    "\n",
    "\n",
    "    # 6Ô∏è‚É£ Get actual survival time for patient i\n",
    "    # Why?\n",
    "    # - This is the ground truth (if known)\n",
    "    actual_survival = y_test_values[i]\n",
    "\n",
    "\n",
    "    # 7Ô∏è‚É£ Check whether the patient died or is censored\n",
    "    # Why?\n",
    "    # - Helps interpret the prediction error\n",
    "    is_event = test_df.iloc[i]['event']\n",
    "    status = \"Died\" if is_event else \"Censored\"\n",
    "\n",
    "\n",
    "    # 8Ô∏è‚É£ Extract key patient features\n",
    "    # Why?\n",
    "    # - Allows understanding WHY the model predicted this value\n",
    "    age = test_df.iloc[i]['age']\n",
    "    metastatic = test_df.iloc[i]['ismetastatic']\n",
    "    surgery = test_df.iloc[i]['hassurgery']\n",
    "    ecog = test_df.iloc[i]['ecogvalue']\n",
    "\n",
    "\n",
    "    # 9Ô∏è‚É£ Print patient number\n",
    "    print(f\"Patient {i+1}:\")\n",
    "\n",
    "\n",
    "    # üîü Print predicted survival\n",
    "    # Why?\n",
    "    # - Shows model output in days and months\n",
    "    print(f\"  Predicted Survival: {pred_survival:.0f} days ({pred_survival/30:.1f} months)\")\n",
    "\n",
    "\n",
    "    # 1Ô∏è‚É£1Ô∏è‚É£ Print actual survival and status\n",
    "    # Why?\n",
    "    # - Shows how close the model was\n",
    "    # - Indicates if survival time is exact or censored\n",
    "    print(f\"  Actual Survival:    {actual_survival:.0f} days ({actual_survival/30:.1f} months) [{status}]\")\n",
    "\n",
    "\n",
    "    # 1Ô∏è‚É£2Ô∏è‚É£ Print patient clinical profile\n",
    "    # Why?\n",
    "    # - Helps interpret the prediction\n",
    "    # - Matches how doctors think\n",
    "    print(\n",
    "        f\"  Age: {age:.0f}, \"\n",
    "        f\"ECOG: {ecog:.0f}, \"\n",
    "        f\"Metastatic: {'Yes' if metastatic else 'No'}, \"\n",
    "        f\"Surgery: {'Yes' if surgery else 'No'}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # 1Ô∏è‚É£3Ô∏è‚É£ Print prediction error ONLY if patient died\n",
    "    # Why?\n",
    "    # - Exact error can be computed only for death events\n",
    "    if is_event:\n",
    "        error = abs(pred_survival - actual_survival)\n",
    "        print(f\"  Prediction Error:   {error:.0f} days ({error/30:.1f} months)\")\n",
    "\n",
    "\n",
    "    # 1Ô∏è‚É£4Ô∏è‚É£ Blank line for readability\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa7cfeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL MODEL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Model Performance:\n",
      "-----------------\n",
      "Gradient Boosting (Test C-index): 0.7247\n",
      "\n",
      "\n",
      "Why Gradient Boosting:\n",
      "---------------------\n",
      "‚úì No proportional hazards assumption\n",
      "‚úì Captures non-linear relationships automatically\n",
      "‚úì Learns feature interactions (e.g., Surgery √ó Stage)\n",
      "‚úì Robust to extreme survival times (Huber loss)\n",
      "‚úì Allows higher weight to death events than censored cases\n",
      "\n",
      "Top 3 Most Important Features:\n",
      "  4. hassurgery (importance = 0.298)\n",
      "  1. age (importance = 0.169)\n",
      "  11. groupstage_Stage IA (importance = 0.122)\n",
      "\n",
      "Limitations:\n",
      "------------\n",
      "‚Ä¢ No native survival-specific loss function\n",
      "‚Ä¢ Censored observations handled approximately\n",
      "‚Ä¢ Requires hyperparameter tuning for optimal results\n",
      "‚Ä¢ Less interpretable than Cox regression coefficients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- L. Final Model Summary ---\n",
    "# Purpose:\n",
    "# - Report final model performance\n",
    "# - Justify why Gradient Boosting was used\n",
    "# - Show interpretability and limitations\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‚úÖ 1. Core performance metric (MOST IMPORTANT)\n",
    "# Why?\n",
    "# - C-index is the standard metric for survival models\n",
    "# - Test score reflects real-world performance\n",
    "print(f\"\"\"\n",
    "Model Performance:\n",
    "-----------------\n",
    "Gradient Boosting (Test C-index): {test_ci:.4f}\n",
    "\"\"\")\n",
    "\n",
    "# ‚úÖ 2. Why Gradient Boosting instead of Cox\n",
    "# Why?\n",
    "# - Explains modeling choice clearly\n",
    "# - Common interview question\n",
    "print(\"\"\"\n",
    "Why Gradient Boosting:\n",
    "---------------------\n",
    "‚úì No proportional hazards assumption\n",
    "‚úì Captures non-linear relationships automatically\n",
    "‚úì Learns feature interactions (e.g., Surgery √ó Stage)\n",
    "‚úì Robust to extreme survival times (Huber loss)\n",
    "‚úì Allows higher weight to death events than censored cases\n",
    "\"\"\")\n",
    "\n",
    "# ‚úÖ 3. Model interpretability (VERY IMPORTANT)\n",
    "# Why?\n",
    "# - Shows the model aligns with clinical intuition\n",
    "# - Builds trust in predictions\n",
    "print(\"Top 3 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"  {idx+1}. {row['Feature']} (importance = {row['Importance']:.3f})\")\n",
    "\n",
    "# ‚úÖ 4. Limitations (DO NOT SKIP ‚Äì shows maturity)\n",
    "# Why?\n",
    "# - Prevents overclaiming\n",
    "# - Required in research and interviews\n",
    "print(\"\"\"\n",
    "Limitations:\n",
    "------------\n",
    "‚Ä¢ No native survival-specific loss function\n",
    "‚Ä¢ Censored observations handled approximately\n",
    "‚Ä¢ Requires hyperparameter tuning for optimal results\n",
    "‚Ä¢ Less interpretable than Cox regression coefficients\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a5cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
